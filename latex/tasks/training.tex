Le immagini vengono inizialmente importate e vengono generati i dataset di \textit{Training} e \textit{testing}. In particolare nel dataset di training sono presenti le prime 6 immagini per ciascun soggetto mentre in quello di testing le restanti 4. Le immagini sono importate sotto forma di vettori \(\{f_1, f_2, \dots, f_N\}\) in \(\mathbb{R}^{mn}\). Il dataset di training contiene \(L = Np\) immagini, dove \(p\) è il rapporto tra dimensione del training set e dimensione del test set, nel nostro caso \(p = 0.6\).

\begin{lstlisting}[language=Python, caption= Data import]
faces_all = np.zeros([num_subjects*num_faces_per_subject, size])
faces_train = np.zeros([train_set_size, size])
faces_test = np.zeros([test_set_size, size])
print('Importing data...')
for i in range(num_subjects): #for each subject
    subject_faces = np.zeros([num_faces_per_subject, size]) #array containing all faces of the subject
    for j in range(num_faces_per_subject): #for each face
        f=path+'/s'+str(i+1)+'/'+str(j+1)+'.pgm' #compose filepath
        img = pgm.read_pgm(f) #read the file (2D array of shape m by n)
        img = img.reshape(size) #reshape the img into a 1D array
        subject_faces[j,:] = img 
    
    faces_all[i*num_faces_per_subject:(i+1)*num_faces_per_subject,:] = subject_faces
    faces_train[i*int(num_faces_per_subject*train_test_ratio):(i+1)*int(num_faces_per_subject*train_test_ratio),:] = \
        subject_faces[0:int(num_faces_per_subject*train_test_ratio),:]
    faces_test[i*int(num_faces_per_subject*(1-train_test_ratio)):(i+1)*int(num_faces_per_subject*(1-train_test_ratio)),:] = \
            subject_faces[int(num_faces_per_subject*train_test_ratio):num_faces_per_subject,:]
\end{lstlisting}

\noindent Viene adesso calcolata la faccia media \(\tilde{f} = \frac{1}{L}  \sum \limits_{l=1}^{L} f_l\) e il dataset di training viene centrato rispetto alla faccia media, ottenendo nuovi vettori \(\phi_l = f_l - \tilde{f}\) con \(l \in \{1, \dots, L\}\).

\begin{lstlisting}[language=Python, caption= Centering data]
L =  faces_train.shape[0]
mean_face = faces_train.mean(axis = 0) #compute mean face
faces_train_center = faces_train-mean_face #centering the dataset (is the matrix Phi^T)
\end{lstlisting}

 \noindent A questo punto l'idea è quella di trovare una particolare base ortonormale \(\{u_1, \dots,u_{K}\}\) con \(u_i \in \mathbb{R}^{mn}, i=1,\dots K\) tale per cui:
\begin{eqnarray*}
    \phi_l = \tilde{f} +  \sum \limits_{n\geq 1} \alpha_n u_n \\
|\alpha_1| \geq |\alpha_2| \geq, ..., \geq |\alpha_{K}|
\end{eqnarray*}
La seconda condizione afferma che la base ortonormale che si sta cercando è tale per cui le componenti sono ordinate per "importanza". Questo concetto è fondamentale per la pratica della riduzione dimensionale: se si riesce a trovare una base di rappresentazione delle immagini per cui le prime componenti sono più importanti delle ultime, allora sarà possibile rappresentare le immagini utilizzando il sottoinsieme delle prime componenti perdendo la minor quantità di informazioni possibile.
\\
\\
Sia \(\lambda_1\) il coefficiente rispetto alla prima componente della base \(u_1\) per la generica immagine \(\phi_l\). 
\[
    \lambda_1 = \left\langle\phi_l, u_1 \right\rangle  
    \]
Sia \(\Phi^T\) la matrice contenente per ciascuna riga le immagini di training:
\[\Phi^T = \begin{bmatrix}
    \phi_1^T \\
    \phi_2^T \\
    \vdots \\
    \phi_L^T
\end{bmatrix}
    \]
\\
Allora il problema della ricerca della prima componente della base \(u_1\) che massimizza in media il modulo del relativo coefficiente per ogni immagine di training si formalizza come:
\begin{equation}
    \max_{\| x \| = 1 } \frac{1}{L}  \sum \limits_{l=1}^{L} | \langle \phi_l, x\rangle|^2 = \max_{\| x \| = 1 } \frac{1}{L} \| \Phi^T x \| ^2_2 = \max_{\| x \| = 1 } \left\langle \frac{1}{L}\Phi \Phi^T x, x \right\rangle = \lambda_1.
\end{equation}
In particolare \(\frac{1}{L}\Phi \Phi^T\) è la matrice di varianza-covarianza campionaria di \(\{\phi_1, ... \phi_L\}\) e \(\lambda_1\) è il suo più grande autovalore in modulo. \(u_1\) sarà pertanto l'autovettore relativo a \(\lambda_1\).
Per la ricerca della seconda componente il procedimento è lo stesso, imponendo l'ortogonalità rispetto alla prima componente:
\[
    \max_{\|x\| = 1, \, x \bot u_1 } \left\langle \frac{1}{L}\Phi \Phi^T x, x \right\rangle = \lambda_2.
\]
La ricerca della particolare base che stiamo cercando si riduce pertanto al problema del calcolo di autovalori e autovettori della matrice  \(\frac{1}{L}\Phi \Phi^T\).
\\
\\
Un'importante dettaglio implementativo è dato dalla dimensione della matrice \(\Phi\Phi^T \in \mathbb{R}^{mn \times mn}\). La quantità \(mn\)  è potenzialmente molto grande (nel nostro caso \(mn \sim 10^3\)), rendendo il calcolo degli autovalori e autovettori un'operazione computazionalmente molto onerosa. Questo problema può tuttavia essere aggirato se si considera che \(\text{Rank}(\Phi\Phi^T) \leq L \) e che gli autovalori della matrice \(\Phi^T \Phi\) sono gli stessi della matrice \(\Phi \Phi^T\). Inoltre:
\[ \Phi\Phi^T x = \lambda x \iff \Phi^T \Phi \Phi^T x = \lambda \Phi^T x
    \]
Pertanto se \(y = \Phi^T x\) è un autovettore di \(\Phi^T \Phi\), allora \(x = \Phi y\) sarà il corrispondente autovettore di \( \Phi\Phi^T \). Il calcolo degli autovettori può pertanto essere eseguito sulla matrice \(\Phi^T \Phi \in \mathbb{R}^{L \times L}\) con \(L \ll mn \) alleggerendo di molto i costi computazionali.
\\
\\
La particolare base che stiamo cercando sarà quindi data da  \(V = \{v_1, \dots, v_L\}\) dove 
\[ v_i = \Phi u_i \quad i = \{1, \dots, L\},\]
\[u_i \text{ autovettore di } \Phi^T\Phi \text{ relativo all'autovalore } \lambda_i ,\]
\[\lambda_1 \geq \lambda_2 \geq \dots \geq \lambda_L.\]
Una volta ottenuta la base \(V\) è possibile scegliere le sue prime \(L'<L\) componenti ottenendo una base \(V' = \{v_1, \dots , v_{L'}\}\) che approssima \(V\). È possibile quantificare la perdita di informazioni se si utilizza la base \(V'\) piuttosto che \(V\) per rappresentare le immagini. In particolare possiamo decidere il numero di componenti trattenute \(L'\) calcolando la varianza trattenuta dalla base:
\begin{equation}\label{variance}
    \frac{ \sum \limits_{l=1}^{L'} \lambda_l}{ \sum \limits_{l=1}^{L}\lambda_l } > \alpha  
\end{equation}
dove \(\alpha \in [0,1]\) è una soglia decisa a priori. Al crescere di \(\alpha\) crescerà il numero di componenti necessarie a trattenere la varianza desiderata.
Quanto spiegato fin ora può essere eseguito attraverso i seguenti comandi:

\begin{lstlisting}[language=Python]
#computing modified covariance matrix (Phi^T * Phi)
cov_mat_mod = 1/L * (faces_train_center @ faces_train_center.transpose()) 
#computing eigenvalues and eigenvectors
eig_val, eig_vec = np.linalg.eig(cov_mat_mod)
#sorting eigenvalues and eigenvectors in decreasing  order
sort_mask = np.argsort(eig_val)[::-1]
eig_val = eig_val[sort_mask]
eig_vec = eig_vec[:, sort_mask]
#computing the cumulative explained variance
explained_variance_cum = (eig_val/eig_val.sum()).cumsum() 

threshold_mask = explained_variance_cum<variance_threshold
num_pcs_kept = (threshold_mask).sum()
#computing eigenvalues of the original covariance matrix
eigenfaces = faces_train_center.transpose() @ eig_vec[:,threshold_mask] 
#normalize by columns the eigenvectors (eigenfaces is now an orthonormal matrix)
eigenfaces = normalize(eigenfaces, axis=0, norm='l2') # is the matrix V'
#project train faces onto the eigenfaces space
faces_train_projected = faces_train_center @ eigenfaces
\end{lstlisting}

\noindent Un dettaglio da non sottovalutare è dato dal fatto che la matrice \(V = [v_1, v_2, \dots v_L]\) è stata ottenuta dal calcolo degli autovettori \(\{u_1, u_2, \dots u_L\}\) ciascuno moltiplicato per \(\Phi\). Se \(\{u_1, u_2, \dots u_L\}\) è un insieme di vettori a norma 1, l'insieme \(\{v_1, v_2,\dots v_L \}\) non lo è, pertanto la matrice \(V\) va normalizzata per colonne.
\\
\\
Una volta calcolata la matrice \(V'\) relativa alla base \(V'\) è possibile proiettare le facce dallo spazio originale a \(V'\):
\[
\phi_l' = V'^T\phi_l \quad l = 1 \dots L
\]
In notazione matriciale:
\[
    \Phi'^T = \begin{bmatrix}
        \phi_1'^T \\
        \phi_2'^T \\
        \vdots \\
        \phi_L'^T
    \end{bmatrix} \quad \Phi'^T = \Phi^T V'  \quad \Phi'^T \in \mathbb{R}^{L \times L'} 
\]
\begin{lstlisting}[language=Python]
#project train faces onto the eigenfaces space
faces_train_projected = faces_train_center @ eigenfaces # Phi'^T = Phi^T * V'
\end{lstlisting}